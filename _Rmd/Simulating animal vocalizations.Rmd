---
title: "Simulating animal vocalizations"
author: "Marcelo Araya-Salas"
date: "2018-02-22"
output: 
  md_document:
    variant: markdown_github
---

This post shows how to simulate animal vocalizations using the new [warbleR](https://cran.r-project.org/package=warbleR) function `sim_songs`. The function allows users to create song with several sub-units and harmonics, which are return as a wave object in the `R` environment. This can have several applications, from simulating song evolution to testing the efficacy of methods to measure acoustic structure for different signal types. 

The function uses a brownian motion model of stochastic diffusion to simulate the changes in frequency (e.g. modulation) across continuous traces of sound (song sub-units or elements). Several parameters of the songs can be customized, which allow users to simulate an wide range of signal structures. Nonetheless, more parameters and diffusion models will be added in future versions.

First install and/or load [warbleR](https://cran.r-project.org/package=warbleR) developmental version (if there is an older [warbleR](https://cran.r-project.org/package=warbleR) version installed it has to be removed first):

```{r sim_song_1, eval=F}
# remove warbleR
remove.packages("warbleR")

# install devtools if not installed
if (!"devtools" %in% installed.packages()[,"Package"])  
  install.packages("devtools")

# and install warbleR from github
devtools::install_github("maRce10/warbleR")
library("warbleR")

```


```{r sim_song_2, echo = FALSE, message = FALSE}

#load packages
library(warbleR)
library(knitr)

# source("~/Dropbox/warbleR/R/sim_songs.R")
# source("~/Dropbox/warbleR/R/fade_env_wrblr_int.R")

opts_chunk$set(comment = "")
opts_knit$set(root.dir = tempdir())
options(width = 150, max.print = 100)

par(mar = c(2, 1.5, 0, 0))

```

The basic song "parameters" that can be customized using the `sim_songs` function are: 

1. The number of sub-units
1. The number of harmonics
1. the carrier frequencies
1. The degree of frequency modulation
1. The duration of sub-units and silences in between

The following code simulates a "song" with 5 sub-units, with a starting frequency of 5 kHz and a single harmonic (fundamental): 

```{r sim_song_3, out.width= 750, dpi = 100}

# simulate song
sm_sng <- sim_songs(n = 5, harms = 1, freqs = 5, seed = 8)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(0, 12), wl = 300, 
                    collevels = seq(-27, 0 , 1), 
        palette = reverse.topo.colors, scale = FALSE)

```

<font size="3"><i>* A seed is used so the same song will be generated every time. If `seed = NULL` (as by default) then a different song will produced each time</i></font>

Longer "repertoires" can be produced by simply increasing `n`:

```{r sim_song_4, out.width= 750, dpi = 100}

# 10 elements
sm_sng <- sim_songs(n = 10, harms = 1, freqs = 5, seed = 16, 
                    sig2 = 0.7, steps = 8)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(0, 12), wl = 300, 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.heat.colors, scale = FALSE)


# 15 elements
sm_sng <- sim_songs(n = 15, harms = 1, freqs = 5, seed = 37, steps = 10)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), wl = 300, 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)

```

 
The amount of modulation can be controlled with the argument `sig2` (just as in the brownian model of evolution). Low values will produce little variation in the frequency slope:

```{r sim_song_5, out.width= 750, dpi = 100}

# low sigma
sm_sng <- sim_songs(n = 5, harms = 1, freqs = 5, seed = 8, sig2 = 0.1)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), wl = 300, 
        collevels = seq(-25, 0 , 1), 
        palette = reverse.topo.colors, scale = FALSE)

```

While higher `sig2` values will generate "faster" frequency changes:

```{r sim_song_6, out.width= 750, dpi = 100}
# high sigma
sm_sng <- sim_songs(n = 5, harms = 1, freqs = 5, seed = 8, sig2 = 0.9)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)


```

Harmonics can also be added to the songs by modifying the `harms` argument:

```{r sim_song_7, out.width= 750, dpi = 100}

# high sigma
sm_sng <- sim_songs(n = 5, harms = 3, freqs = 5, seed = 8, sig2 = 0.9)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)

```

The `steps` argument allows to define the length of the time series generated by the underlying brownian motion function. This time series is simply the frequency values at each time window (after some spline smoothing) of the song elements. Lower `steps` values will produce less modulated songs (other things equal):

```{r sim_song_8, out.width= 750, dpi = 100}

# high sigma
sm_sng <- sim_songs(n = 5, harms = 3, freqs = 5, seed = 8, 
                    sig2 = 0.9, steps = 4)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)

```

Higher `steps` values will increase modulation:

```{r sim_song_9, out.width= 750, dpi = 100}

# high sigma
sm_sng <- sim_songs(n = 5, harms = 3, freqs = 5, seed = 8, 
                    sig2 = 0.9, steps = 70)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)

```

The duration of the sub-units and gaps between elements can also be specified for each of the items:

```{r sim_song_10, out.width= 750, dpi = 100}

durs <- seq(0.5, 0.1, length.out = 5) 
gaps <- c(0.2, 0.15, 0.1, 0.08, 0.05, 0.2)

# high sigma
sm_sng <- sim_songs(n = 5, harms = 3, freqs = 5, seed = 84, sig2 = 0.1, 
                    steps = 20, durs = durs, gaps = gaps)

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-27, 0 , 1), 
        palette = reverse.terrain.colors, scale = FALSE)

```

Users can also adjust the relative amplitude of the harmonics. The following code puts the highest energy on the second harmonic (e.g. the dominant frequency) using the `amps` argument:

```{r sim_song_11, out.width= 750, dpi = 100}

# high sigma
sm_sng <- sim_songs(n = 4, harms = 5, freqs = 5, seed = 24, 
                    amps = c(0.7, 1, 0.5, 0.3, 0.25))

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(1, 12), 
        collevels = seq(-23, 0 , 1), 
        palette = reverse.topo.colors, scale = FALSE)


```

The simulated song can be played with the `play` function from [tuneR](https://cran.r-project.org/package=tuneR) or by saving the wave file and opening it in a regular audio player. Here is an example of a 20 element simulated song:

```{r sim_song_12, out.width= 750, dpi = 100}

#set variable durations 
durs <- rnorm(n = 20, mean = 0.21, sd = 0.05)

#and variable gaps
gaps <- rnorm(n = 21, mean = 0.12, sd = 0.06)

# and frequencies
freqs <- rnorm(n = 20, mean = 3, sd = 0.7)

# high sigma
sm_sng <- sim_songs(n = 20, harms = 3, seed = 25, 
                    durs = durs, gaps = gaps, steps = 4, 
                    freqs = freqs, diff_fun = "BB")

#plot spectro
spectro(sm_sng, grid = FALSE, flim = c(0, 9), 
        collevels = seq(-23, 0 , 1), 
        palette = reverse.topo.colors, scale = FALSE)

```

```{r sim_song_13, eval= F}

# save it as a wave file
writeWave(sm_sng, "simulated_song.wav")

```

And this is how it sounds:

<audio controls style="width: 700px;">
   <source src="/img/simulated_song.mp3" type="audio/mpeg">
</audio>


In the above example the "BB" diffusion model was used to simulate the sounds (argument `diff_fun`). This method forces the sub-units to start and end at the same frequency. Note also that combining random variables to set durations and gaps can help create more realistic songs. 

Finally, the background noise level (argument `bgn`), sampling rate (`samp.rate`) amd amplitude fade-in (`fin`) and fade-out (`fout` & `shape`) can also be adjusted.

More options will be added in future versions. Suggestions are welcome. I am particularly interested on diffusion models (or any other algorithm) that can generate different types of signals, ideally even more similar to the ones found in nature.

Please report any bugs [here](https://github.com/maRce10/warbleR/issues). 